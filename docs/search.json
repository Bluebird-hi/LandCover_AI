[
  {
    "objectID": "naip-studyarea.html",
    "href": "naip-studyarea.html",
    "title": "Download the NAIP Images of the study area",
    "section": "",
    "text": "import os, os.path\nfrom pystac_client import Client\nimport planetary_computer as pc\nimport rioxarray\nimport rasterio as rio\nimport fiona\nimport pyproj\nfrom shapely.geometry import shape, Point, Polygon, mapping\nfrom functools import partial\nfrom shapely.ops import transform\nimport urllib.request\nimport numpy as np\nimport geopandas as gpd\nimport pyproj\n\npc.settings.set_subscription_key(\"st=2022-06-01T22%3A55%3A32Z&se=2022-06-02T23%3A40%3A32Z&sp=rl&sv=2020-06-12&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-06-02T20%3A23%3A33Z&ske=2022-06-09T20%3A23%3A33Z&sks=b&skv=2020-06-12&sig=U5e1SoZGZqIcunum5BKWcmsVi2bmS1tBsr94LPI%2BLoc%3D\")\nimport pystac_client\nimport planetary_computer\n\ncatalog = pystac_client.Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\nimport os\nimport fiona\nfrom shapely.geometry import shape, mapping\nfrom shapely.ops import transform as shapely_transform\nfrom pyproj import Transformer\n\n# Open your shapefile\nshpfile = 'data/StudyArea.shp'\n\nwith fiona.open(shpfile, 'r') as src:\n    # Get the original CRS\n    print(\"Original CRS:\", src.crs)\n\n    # Create a transformer to EPSG:4326\n    transformer = Transformer.from_crs(src.crs, \"EPSG:4326\", always_xy=True)\n\n    # Read and reproject the first feature (assuming single polygon)\n    for feat in src:\n        # Original geometry\n        geom = shape(feat['geometry'])\n        \n        # Reprojected geometry\n        area_of_interest_city = shapely_transform(transformer.transform, geom)\n        \n        break  # Only process the first feature for now\n\n    # After loading the layer, get bounds (in original CRS)\n    left, bottom, right, top = src.bounds\n\n# Transform the bounding box coordinates to EPSG:4326\nminx, miny = transformer.transform(left, bottom)\nmaxx, maxy = transformer.transform(right, top)\n\n# Create bounding box as GeoJSON-style Polygon\narea_of_interest = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [minx, miny],\n            [maxx, miny],\n            [maxx, maxy],\n            [minx, maxy],\n            [minx, miny],\n        ]\n    ],\n}\nprint(area_of_interest)\n\nOriginal CRS: EPSG:3857\n{'type': 'Polygon', 'coordinates': [[[-75.16798899969106, 39.952947999855134], [-75.14802900001656, 39.952947999855134], [-75.14802900001656, 39.96342200029067], [-75.16798899969106, 39.96342200029067], [-75.16798899969106, 39.952947999855134]]]}\n## check on GEE, https://developers.google.com/earth-engine/datasets/catalog/USDA_NAIP_DOQQ\n## https://code.earthengine.google.com/?scriptPath=Examples%3ADatasets%2FUSDA%2FUSDA_NAIP_DOQQ&hl=zh-cn\nrange_time = '2022-01-01' + '/' + '2022-12-31'\n# 2010, 2013, 2017, 2019, 2022, 2023 (1)\nsearch_new = catalog.search(\n    collections=[\"naip\"], intersects=area_of_interest, datetime=range_time\n)\n\nitems_tiles = search_new.item_collection()\n\nprint(f\"{len(items_tiles)} Items found in the 'new' range\")\n\n2 Items found in the 'new' range\noutfolder = 'data/2022'\nif not os.path.exists(outfolder): os.mkdir(outfolder)\n\n## loop all the intersected tiles and download them all\nfor item in items_tiles:\n    # href = pc.sign(item.assets[\"image\"].href)\n    href = item.assets[\"image\"].href\n    print(href)\n    \n    outfilename = os.path.join(outfolder, item.id + \".tif\")\n    urllib.request.urlretrieve(href, outfilename)\n\nhttps://naipeuwest.blob.core.windows.net/naip/v002/nj/2022/nj_060cm_2022/39075/m_3907507_ne_18_060_20220630.tif?st=2025-04-26T02%3A38%3A51Z&se=2025-04-27T03%3A23%3A51Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-04-26T16%3A24%3A38Z&ske=2025-05-03T16%3A24%3A38Z&sks=b&skv=2024-05-04&sig=gvFEo%2B6HoZHnNZ1%2B5NcxjJibhUCG8Z8NgdF/swBWkDg%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2022/pa_060cm_2022/39075/m_3907507_ne_18_060_20220510.tif?st=2025-04-26T02%3A38%3A51Z&se=2025-04-27T03%3A23%3A51Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-04-26T16%3A24%3A38Z&ske=2025-05-03T16%3A24%3A38Z&sks=b&skv=2024-05-04&sig=gvFEo%2B6HoZHnNZ1%2B5NcxjJibhUCG8Z8NgdF/swBWkDg%3D",
    "crumbs": [
      "Appendix",
      "NAIP Preparation"
    ]
  },
  {
    "objectID": "naip-studyarea.html#mosaic",
    "href": "naip-studyarea.html#mosaic",
    "title": "Download the NAIP Images of the study area",
    "section": "Mosaic",
    "text": "Mosaic\n\n# This function is used to mosaic geotiffs in the input folder\n# Parameters:\n#     dirpath: the folder name of the tif files\n#     outfile: the output file of the mosaiced geotiff image\n\nimport rasterio\n# import ogr\nimport fiona\nimport os, os.path\nfrom rasterio.merge import merge\nimport glob\nfrom shapely.geometry import Polygon\nfrom shapely.geometry import shape\n\n\n# mosaicRasters(folder, os.path.join(root, 'naip-atlanta.tif'))\ninputfolder= 'data/2022'\noutfile = 'data/mosacied-naip-2022.tif'\n\n# start to mosaic the raster tiles\ntiflist = []\n\nfor file in os.listdir(inputfolder):    \n    if file.endswith('.tif'):\n        tiffile = os.path.join(inputfolder, file)\n        tiflist.append(tiffile)\n\n\nsrc_files_to_mosaic = []\nfor fp in tiflist:\n    try:\n        tile_src = rasterio.open(fp)\n        tile_bounds = tile_src.bounds\n        \n        src_files_to_mosaic.append(tile_src)\n    except:\n        continue\n\nprint('The number of mosaiced tiles is:', len(src_files_to_mosaic))\n\n# the method can be set as min, max..\nmosaic, out_trans = merge(src_files_to_mosaic) #, method='max'\nprint('You have mosaiced the results')\n\n\n# Prepare the schema of the output mosacied image\nout_meta = tile_src.meta.copy()\nout_meta.update({\"driver\": \"GTiff\",\n                  \"height\": mosaic.shape[1],\n                  \"width\": mosaic.shape[2],\n                  \"transform\": out_trans, \n                  \"compress\": 'lzw',\n                  'BIGTIFF': 'YES'\n                  }\n               )\n\n#out_fp = os.path.join(dirpath, 'atlanta-naip.tif')\nwith rasterio.open(outfile, \"w\", **out_meta) as dest:\n     dest.write(mosaic)\n\nThe number of mosaiced tiles is: 2\nYou have mosaiced the results\n\n\n\nfrom matplotlib import pyplot as plt\ndef display_naip_tile(filename, dsfactor = 2):\n    \"\"\"\n    Display a NAIP tile using rasterio.\n    \n    dsfactor: downsample factor\n    For .mrf-formatted tiles (which span multiple files), 'filename' should refer to the \n    .mrf file.\n    \"\"\"\n    \n    # NAIP tiles are enormous; downsize for plotting in this notebook\n    \n    with rasterio.open(filename) as raster:\n        # rasterio uses 1-based indexing for channels.\n        h = int(raster.height/dsfactor)\n        w = int(raster.width/dsfactor)\n        print('Resampling to {},{}'.format(h,w))\n        ir = raster.read(4, out_shape=(1, h, w))\n        r = raster.read(1, out_shape=(1, h, w))\n        g = raster.read(2, out_shape=(1, h, w))\n        \n    cir = np.dstack((ir,r,g))\n    fig = plt.figure(figsize=(7.5, 7.5), dpi=100, edgecolor='k')\n    plt.imshow(cir)\n    raster.close()\n    \nnaip_file = 'data/mosacied-naip-2022.tif'\ndisplay_naip_tile(naip_file)\n\nResampling to 6242,4922",
    "crumbs": [
      "Appendix",
      "NAIP Preparation"
    ]
  },
  {
    "objectID": "naip-studyarea.html#mask-the-mosaiced-raster-to-study-area",
    "href": "naip-studyarea.html#mask-the-mosaiced-raster-to-study-area",
    "title": "Download the NAIP Images of the study area",
    "section": "Mask the mosaiced raster to study area",
    "text": "Mask the mosaiced raster to study area\n\n# Reproject the shapefile to match the raster\nfrom pyproj import Transformer\nimport geopandas as gpd\n# Open raster to get CRS\nwith rasterio.open(\"data/mosacied-naip-2013.tif\") as src:\n    raster_crs = src.crs  # Save raster's CRS\nshp = gpd.read_file(\"data/StudyArea.shp\")\nshp = shp.to_crs(src.crs)  # Reproject to match raster\nshp.to_file(\"data/StudyArea_reprojected_mosaic.shp\")\n\n\nimport rasterio\nimport fiona\n\n# Check raster CRS\nwith rasterio.open('data/mosacied-naip-2023.tif') as src:\n    print(\"Raster CRS:\", src.crs)\n\n# Check shapefile CRS\nwith fiona.open('data/StudyArea_reprojected_mosaic.shp') as shp:\n    print(\"Shapefile CRS:\", shp.crs)\n\nRaster CRS: EPSG:26918\nShapefile CRS: EPSG:26918\n\n\n\nimport fiona\n\ninput_value_raster = 'data/mosacied-naip-2022.tif'\nshpfile = 'data/StudyArea_reprojected_mosaic.shp'\nout_raster = 'data/mask2022-naip.tif'\n\n\nwith fiona.open(shpfile, \"r\") as shapefile:\n    shapes = [feature[\"geometry\"] for feature in shapefile]\n\nwith rasterio.open(input_value_raster) as src:\n    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n    out_meta = src.meta\n\nout_meta.update({\"driver\": \"GTiff\",\n                 \"height\": out_image.shape[1],\n                 \"width\": out_image.shape[2],\n                 \"count\": out_image.shape[0],  # Ensure correct number of bands\n                 \"dtype\": out_image.dtype,  # Ensure correct data type\n                 \"compress\": None,\n                 \"transform\": out_transform})\n\nwith rasterio.open(out_raster, \"w\", **out_meta) as dest:\n    dest.write(out_image)\n\ndisplay_naip_tile('data/mask2022-naip.tif')\n\nResampling to 970,1422",
    "crumbs": [
      "Appendix",
      "NAIP Preparation"
    ]
  },
  {
    "objectID": "2.model-training.html",
    "href": "2.model-training.html",
    "title": "Model Training",
    "section": "",
    "text": "Train a machine learning model based on the land use/cover map and NAIP imagery in Philadelphia.\nBy Luming Xu, May 5, 2025 ## Prepare the dataset for training\nimport os, os.path\nimport rasterio\nfrom rasterio.mask import mask\nimport geopandas as gpd\nimport numpy as np\nfrom shapely.geometry import mapping\nfrom rasterio.enums import Resampling",
    "crumbs": [
      "Reproducible Analysis",
      "Model Training"
    ]
  },
  {
    "objectID": "2.model-training.html#predicting-on-the-image",
    "href": "2.model-training.html#predicting-on-the-image",
    "title": "Model Training",
    "section": "2 Predicting on the image",
    "text": "2 Predicting on the image\n\nfrom rasterio.plot import show\nfrom rasterio.plot import show_hist\nfrom rasterio.windows import Window\nfrom rasterio.plot import reshape_as_raster, reshape_as_image\n\n\n2.1 Apply the trained model to four tiles of Chicago\n\n# Load the saved model\n# best_model_svm = joblib.load(\"C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/best_svm_model.pkl\")\n# print(\"Loaded the best SVM model.\")\n\nimport os\n# from sklearn.externals import joblib  # Load the trained model\n# Define input and output directories\ninput_dir = \"C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-naip\"\noutput_dir = \"C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Load trained classification model (update path to your model file)\n# model_path = \"path_to_your_trained_model.pkl\"\n# model = joblib.load(model_path)\n\n# Loop through all TIFF files in the input directory\nfor filename in os.listdir(input_dir):\n    if filename.endswith(\".tif\"):\n        input_path = os.path.join(input_dir, filename)\n        output_path = os.path.join(output_dir, f\"classified_{filename}\")\n        \n        with rasterio.open(input_path) as src:\n            img = src.read()\n            meta = src.meta\n            reshaped_img = reshape_as_image(img)\n            \n            # Predict class labels\n            class_prediction = svm_model.predict(reshaped_img.reshape(-1, img.shape[0]))\n            class_prediction = class_prediction.reshape(reshaped_img[:, :, 0].shape)\n            \n            # Update metadata and save classified raster\n            meta.update(dtype=rasterio.uint8, count=1)\n            with rasterio.open(output_path, \"w\", **meta) as dst:\n                dst.write(class_prediction.astype(rasterio.uint8), 1)\n        \n        print(f\"Processed {filename} and saved to {output_path}\")\n\nprint(\"Classification completed for all tiles.\")\n\nProcessed mask2022-naip.tif and saved to C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified\\classified_mask2022-naip.tif\nClassification completed for all tiles.\n\n\n\n\n2.2 Plot\n\nimport rasterio\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nmosaic_path = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2017-naip.tif'\n\n# Open the raster file\nwith rasterio.open(mosaic_path) as src:\n    classified_img = src.read(1)  # Read the first (only) band\n    nodata_value = src.nodata  # Check the NoData value, if exists\n\n# Check unique values in the raster (to understand classification)\nprint(f\"Unique values in the classified raster: {np.unique(classified_img)}\")\nprint(f\"NoData value: {nodata_value}\")\n\n# Handle NoData values (e.g., replace them with a specific value if needed)\nif nodata_value is not None:\n    classified_img[classified_img == nodata_value] = 0  # Replace NoData with 0 or any appropriate value\n\n# Plot the classified raster\n# Plot the classified raster\nplt.figure(figsize=(10, 8))\nplt.imshow(classified_img, cmap=\"tab10\")  # 'tab10' provides distinct colors\nplt.colorbar(label=\"Land Cover Class\")  # Optional colorbar\nplt.title(\"2010\")\nplt.axis(\"off\")  # Hide axis ticks\nplt.show()\n\nUnique values in the classified raster: [2 6]\nNoData value: None\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Train an SVM Classifier (RBF Kernel for non-linear decision boundaries)\nsvm_model = SVC(kernel=\"rbf\", C=10, gamma=\"scale\")\nsvm_model.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = svm_model.predict(X_test)\n\n# Evaluate Model\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))",
    "crumbs": [
      "Reproducible Analysis",
      "Model Training"
    ]
  },
  {
    "objectID": "2.model-training.html#compute-ndvi",
    "href": "2.model-training.html#compute-ndvi",
    "title": "Model Training",
    "section": "Compute NDVI",
    "text": "Compute NDVI\n\nimport rio\nout_tif = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/CT-veg.tif'\n\ninfolder = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-naip'\noutfolder = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data'\n\nif not os.path.exists(outfolder):\n    os.mkdir(outfolder)\n\n\nfor file in os.listdir(infolder):\n    tiffile = os.path.join(infolder, file)\n    \n    # read the different bands of the raster data\n    if not tiffile.endswith('.tif'): continue\n    naip_dataset = rio.open(tiffile)\n    green = np.float32(naip_dataset.read(3))\n    red = np.float32(naip_dataset.read(2))\n    nir = np.float32(naip_dataset.read(1))\n\n    # here add 0.0000001 is to make sure the nir+red is not zero\n    ndvi = (nir - red)/(nir + red + 0.000001)\n    \n    # extract the vegetation based on the ndvi\n    veg = np.zeros((ndvi.shape[0], ndvi.shape[1]), dtype = np.uint16)\n    veg[ndvi &gt; 0] = 1\n    \n    \n    # prepare the schema of the new tiles\n    out_meta = naip_dataset.meta.copy()\n\n    # update the schema of the ndvi image, because it is different from teh raw naip image, like only one band\n    out_meta.update({'count': 1,\n                    'dtype': 'uint16',\n                     \"height\": ndvi.shape[0],\n                     \"width\": ndvi.shape[1],\n    #                  \"transform\": out_transform,\n                     \"crs\": naip_dataset.crs, \n                     'compress': 'lzw'}\n                   )\n    \n    \n    # this is required, because rio will use three dimension, even this is single band image\n    veg = veg.reshape(1, veg.shape[0], veg.shape[1])\n    \n    out_tif = os.path.join(outfolder, file)\n    with rio.open(out_tif, \"w\", **out_meta) as dest:\n        dest.write(veg)\n    \n\n\n2.3 Visualize the land use map using GIS desktop\n\n\n\nClassified Land Use Map",
    "crumbs": [
      "Reproducible Analysis",
      "Model Training"
    ]
  },
  {
    "objectID": "1-index.html#in-brief",
    "href": "1-index.html#in-brief",
    "title": "Exploring Land Cover Change Around the Philadelphia Chinatown Stitch",
    "section": "In Brief",
    "text": "In Brief",
    "crumbs": [
      "About Page"
    ]
  },
  {
    "objectID": "1-index.html#author",
    "href": "1-index.html#author",
    "title": "Exploring Land Cover Change Around the Philadelphia Chinatown Stitch",
    "section": "Author",
    "text": "Author\n\n\n\n\nLuming Xu\n\n\nMaster of Urban Spatial Analytics’25 at UPenn\nI’m interested in smart city and urban vitality :)",
    "crumbs": [
      "About Page"
    ]
  },
  {
    "objectID": "1.data-preparation.html",
    "href": "1.data-preparation.html",
    "title": "Data Preparation",
    "section": "",
    "text": "Wrangle land cover raster and NAIP image of Philadelphia.\nWrangle NAIP images of the study area.\nBy Luming Xu, May 5, 2025\n# !pip install path\n# !pip install rasterio\n# !pip install shapely\nimport os, os.path\nfrom path import Path\nimport shutil\nimport rasterio as rio\nimport rasterio\nfrom rasterio.windows import get_data_window\nfrom rasterio.windows import Window\nimport rasterio.mask\nimport json\nimport random\nimport numpy as np\nimport argparse\nfrom pystac_client import Client\nimport planetary_computer as pc\nimport rioxarray\nimport fiona\nimport pyproj\nfrom shapely.geometry import shape, Point, Polygon, mapping\nfrom functools import partial\nfrom shapely.ops import transform\nimport urllib.request\nimport geopandas as gpd\nfrom matplotlib import pyplot as plt\n\npc.settings.set_subscription_key(\"st=2022-06-01T22%3A55%3A32Z&se=2022-06-02T23%3A40%3A32Z&sp=rl&sv=2020-06-12&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-06-02T20%3A23%3A33Z&ske=2022-06-09T20%3A23%3A33Z&sks=b&skv=2020-06-12&sig=U5e1SoZGZqIcunum5BKWcmsVi2bmS1tBsr94LPI%2BLoc%3D\")",
    "crumbs": [
      "Reproducible Analysis",
      "Data Preparation"
    ]
  },
  {
    "objectID": "1.data-preparation.html#wrangle-land-cover-and-naip-imagery",
    "href": "1.data-preparation.html#wrangle-land-cover-and-naip-imagery",
    "title": "Data Preparation",
    "section": "1. Wrangle land cover and NAIP imagery",
    "text": "1. Wrangle land cover and NAIP imagery\n\n2018 Land cover raster\nThe Philadelphia Land Cover Raster provides data on the types of surfaces in Philadelphia in 2018. Seven land cover classes were mapped: (1) tree canopy, (2) grass/shrub, (3) bare earth, (4) water, (5) buildings, (6) roads, and (7) other paved surfaces. The primary sources used to derive this land cover layer were 2018 LiDAR data and 2017 NAIP imagery.\n\nroot = 'C:/Users/19397/Documents/GitHub/MUSA_6950/NationalParks_AI'\n\nlandcover_file = os.path.join(root, 'data/landcover_2018_philly.tif')\n\n\n\n2017 NAIP imagery\n\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=pc.sign_inplace,\n)\n# Open your shapefile\nshpfile = os.path.join(root, 'data/city_limit_4326.shp')\n\nlyr = fiona.open(shpfile)\nfor feat in lyr:\n    area_of_interest_city = feat['geometry']\n    # print(area_of_interest)\n\nleft, bottom, right, top = lyr.bounds\narea_of_interest = {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n        [\n            [left, bottom],\n            [right, bottom],\n            [right, top],\n            [left, top],\n            [left, bottom],\n        ]\n    ],\n}\n\nprint(area_of_interest)\n\n{'type': 'Polygon', 'coordinates': [[[-75.28030313034645, 39.867465570687145], [-74.9557457320632, 39.867465570687145], [-74.9557457320632, 40.137927528193686], [-75.28030313034645, 40.137927528193686], [-75.28030313034645, 39.867465570687145]]]}\n\n\n\n## check on GEE, https://developers.google.com/earth-engine/datasets/catalog/USDA_NAIP_DOQQ\n## https://code.earthengine.google.com/?scriptPath=Examples%3ADatasets%2FUSDA%2FUSDA_NAIP_DOQQ&hl=zh-cn\nrange_time = '2017-04-01' + '/' + '2017-08-31'\n# 2010, 2013, 2017, 2019, 2022, 2023 (1)\nsearch_new = catalog.search(\n    collections=[\"naip\"], intersects=area_of_interest, datetime=range_time\n)\n\nitems_tiles = search_new.item_collection()\n\nprint(f\"{len(items_tiles)} Items found in the 'new' range\")\n\n43 Items found in the 'new' range\n\n\n\noutfolder = os.path.join(root, 'data/naip_2017_philly')\nif not os.path.exists(outfolder): os.mkdir(outfolder)\n\n## loop all the intersected tiles and download them all\nfor item in items_tiles:\n    # href = pc.sign(item.assets[\"image\"].href)\n    href = item.assets[\"image\"].href\n    print(href)\n    \n    outfilename = os.path.join(outfolder, item.id + \".tif\")\n    urllib.request.urlretrieve(href, outfilename)\n\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007564_se_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007564_nw_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007564_ne_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007563_sw_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007563_se_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007563_nw_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007563_ne_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007556_sw_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007555_sw_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007555_se_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40074/m_4007457_sw_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40074/m_4007457_nw_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40074/m_4007449_sw_18_1_20170612.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/40075/m_4007564_sw_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907515_nw_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907514_ne_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907508_nw_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907508_ne_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907507_sw_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907507_se_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907507_nw_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907507_ne_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907506_se_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\nhttps://naipeuwest.blob.core.windows.net/naip/v002/pa/2017/pa_100cm_2017/39075/m_3907506_ne_18_1_20170611.tif?st=2025-05-13T16%3A22%3A19Z&se=2025-05-14T17%3A07%3A19Z&sp=rl&sv=2024-05-04&sr=c&skoid=9c8ff44a-6a2c-4dfb-b298-1c9212f64d9a&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2025-05-14T15%3A49%3A12Z&ske=2025-05-21T15%3A49%3A12Z&sks=b&skv=2024-05-04&sig=RMEf0MqGCLbAlZKMO3uG0laKecaUrdclGdm3q%2BnRUOQ%3D\n\n\n\n# This function is used to mosaic geotiffs in the input folder\n# Parameters:\n#     dirpath: the folder name of the tif files\n#     outfile: the output file of the mosaiced geotiff image\n\n\nfrom rasterio.merge import merge\nimport glob\n\n\n# mosaicRasters(folder, os.path.join(root, 'naip-atlanta.tif'))\ninputfolder= os.path.join(root, 'data/naip_2017_philly')\noutfile = os.path.join(root, 'data/mosacied_naip_2017_philly.tif')\n\n# start to mosaic the raster tiles\ntiflist = []\n\nfor file in os.listdir(inputfolder):    \n    if file.endswith('.tif'):\n        tiffile = os.path.join(inputfolder, file)\n        tiflist.append(tiffile)\n\n\nsrc_files_to_mosaic = []\nfor fp in tiflist:\n    try:\n        tile_src = rasterio.open(fp)\n        tile_bounds = tile_src.bounds\n        \n        src_files_to_mosaic.append(tile_src)\n    except:\n        continue\n\nprint('The number of mosaiced tiles is:', len(src_files_to_mosaic))\n\n# the method can be set as min, max..\nmosaic, out_trans = merge(src_files_to_mosaic) #, method='max'\nprint('You have mosaiced the results')\n\n\n# Prepare the schema of the output mosacied image\nout_meta = tile_src.meta.copy()\nout_meta.update({\"driver\": \"GTiff\",\n                  \"height\": mosaic.shape[1],\n                  \"width\": mosaic.shape[2],\n                  \"transform\": out_trans, \n                  \"compress\": 'lzw',\n                  'BIGTIFF': 'YES'\n                  }\n               )\n\n#out_fp = os.path.join(dirpath, 'atlanta-naip.tif')\nwith rasterio.open(outfile, \"w\", **out_meta) as dest:\n     dest.write(mosaic)\n\nThe number of mosaiced tiles is: 43\nYou have mosaiced the results\n\n\n\n# Reproject the shapefile to match the raster\nfrom pyproj import Transformer\nimport geopandas as gpd\n# Open raster to get CRS\nwith rasterio.open(\"data/mosacied_naip_2017_philly.tif\") as src:\n    raster_crs = src.crs  # Save raster's CRS\nshp = gpd.read_file(\"data/city_limit_4326.shp\")\nshp = shp.to_crs(src.crs)  # Reproject to match raster\nshp.to_file(\"data/city_limit_proj.shp\")\n\n# Check raster CRS\nwith rasterio.open('data/mosacied_naip_2017_philly.tif') as src:\n    print(\"Raster CRS:\", src.crs)\n# Check shapefile CRS\nwith fiona.open('data/city_limit_proj.shp') as shp:\n    print(\"Shapefile CRS:\", shp.crs)\n\nRaster CRS: EPSG:26918\nShapefile CRS: EPSG:26918\n\n\n\ninput_value_raster = 'data/mosacied_naip_2017_philly.tif'\nshpfile = 'data/city_limit_proj.shp'\nout_raster = 'data/masked_naip_2017_philly.tif'\n\n\nwith fiona.open(shpfile, \"r\") as shapefile:\n    shapes = [feature[\"geometry\"] for feature in shapefile]\n\nwith rasterio.open(input_value_raster) as src:\n    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n    out_meta = src.meta\n\nout_meta.update({\"driver\": \"GTiff\",\n                 \"height\": out_image.shape[1],\n                 \"width\": out_image.shape[2],\n                 \"count\": out_image.shape[0],  # Ensure correct number of bands\n                 \"dtype\": out_image.dtype,  # Ensure correct data type\n                 \"compress\": None,\n                 \"transform\": out_transform})\n\nwith rasterio.open(out_raster, \"w\", **out_meta) as dest:\n    dest.write(out_image)\n\ndef display_naip_tile(filename, dsfactor = 2):\n    \"\"\"\n    Display a NAIP tile using rasterio.\n    \n    dsfactor: downsample factor\n    For .mrf-formatted tiles (which span multiple files), 'filename' should refer to the \n    .mrf file.\n    \"\"\"\n    \n    # NAIP tiles are enormous; downsize for plotting in this notebook\n    \n    with rasterio.open(filename) as raster:\n        # rasterio uses 1-based indexing for channels.\n        h = int(raster.height/dsfactor)\n        w = int(raster.width/dsfactor)\n        print('Resampling to {},{}'.format(h,w))\n        ir = raster.read(4, out_shape=(1, h, w))\n        r = raster.read(1, out_shape=(1, h, w))\n        g = raster.read(2, out_shape=(1, h, w))\n        \n    cir = np.dstack((ir,r,g))\n    fig = plt.figure(figsize=(7.5, 7.5), dpi=100, edgecolor='k')\n    plt.imshow(cir)\n    raster.close()\n\ndisplay_naip_tile('data/masked_naip_2017_philly.tif')\n\nResampling to 14999,13854",
    "crumbs": [
      "Reproducible Analysis",
      "Data Preparation"
    ]
  },
  {
    "objectID": "1.data-preparation.html#wrangle-naip-images-of-the-study-area",
    "href": "1.data-preparation.html#wrangle-naip-images-of-the-study-area",
    "title": "Data Preparation",
    "section": "2. Wrangle NAIP images of the study area",
    "text": "2. Wrangle NAIP images of the study area\nThe wrangling process is the same as acquiring the 2017 NAIP imagery of Philadelphia. Based on what I researched about the NAIP images and the development of the study area, 2010, 2017 and 2023 images are processed.\n\ndisplay_naip_tile('data/mask2010-naip.tif')\n\nResampling to 582,854\n\n\n\n\n\n\n\n\n\n\ndisplay_naip_tile('data/mask2017-naip.tif')\n\nResampling to 582,854\n\n\n\n\n\n\n\n\n\n\ndisplay_naip_tile('data/mask2023-naip.tif')\n\nResampling to 1940,2844",
    "crumbs": [
      "Reproducible Analysis",
      "Data Preparation"
    ]
  },
  {
    "objectID": "3.PLOT.html",
    "href": "3.PLOT.html",
    "title": "Land Cover Change Analysis",
    "section": "",
    "text": "from matplotlib import pyplot as plt\n\n\nroot = 'C:/Users/19397/Documents/GitHub/MUSA_6950/NationalParks_AI'\nmosaic_path = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/mosacied-lu-chicago.tif'\n# Open the raster file\nwith rasterio.open(mosaic_path) as src:\n    classified_img = src.read(1)  # Read the first (only) band\n\n# Plot the classified raster\nplt.figure(figsize=(10, 8))\nplt.imshow(classified_img, cmap=\"tab10\")  # 'tab10' provides distinct colors\nplt.colorbar(label=\"Land Cover Class\")  # Optional colorbar\nplt.title(\"Classified Land Cover Map, A Part of Chicago\")\nplt.axis(\"off\")  # Hide axis ticks\nplt.show()\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nimport matplotlib.colors as mcolors\n\n# Path to the classified raster file\nmosaic_path = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2022-naip.tif'\n\n# Open the raster file to access the data and metadata\nwith rasterio.open(mosaic_path) as src:\n    classified_img = src.read(1)  # Read the first (only) band\n    nodata_value = src.nodata  # Check the NoData value, if exists\n    pixel_size = src.res  # This gives (pixel_width, pixel_height) in feet\n    pixel_area = pixel_size[0] * pixel_size[1]  # Pixel area in square feet\n\n# Handle NoData values (e.g., replace them with a specific value if needed)\nif nodata_value is not None:\n    classified_img[classified_img == nodata_value] = 0  # Replace NoData with 0 or any appropriate value\n\n# Get unique classes and their counts\nunique_classes, counts = np.unique(classified_img, return_counts=True)\n\n# Calculate the area for each class (in square feet)\nclass_areas_ft2 = counts * pixel_area  # Area = pixel count * pixel area (square feet)\n\n# Define new colors for the bars\ncmap = mcolors.ListedColormap([\n    '#B3AFA5',  # Class 1 - Barren Land\n    '#E1CDCD',  # Class 2 - Developed Open Space\n    '#AA1E22',  # Class 3 - Buildings\n    '#FFFFFF',  # Class 4 - Background\n    '#6CAB67',  # Class 5 - Green Space (Park)\n    '#DC9881',  # Class 6 - Developed Low Density\n    '#e377c2'   # Class 7 - Other\n])\n\n# Create the legend labels corresponding to the class values\nlegend_labels = [\n    'Barren Land', \n    'Developed Open Space', \n    'Buildings', \n    'Background', \n    'Green Space (Park)', \n    'Developed Low Density', \n    'Other'\n]\n\n# Plotting the bar plot for class areas\nplt.figure(figsize=(10, 6))\n\n# Bar colors corresponding to the classes\nbar_colors = cmap(range(len(unique_classes)))\n\n# Plot the bars\nplt.bar(unique_classes, class_areas_ft2, color=bar_colors)\n\n# Add title and axis labels\nplt.xlabel('Class')\nplt.ylabel('Area (square feet)')\nplt.title('2022')\n\n# Set x-axis labels to the class names and rotate them by 45 degrees\nplt.xticks(unique_classes, legend_labels, rotation=45, ha='right')\n\n# Create a custom legend for the classes\nhandles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cmap(i), markersize=10) for i in range(7)]\nplt.legend(handles, legend_labels, title=\"Classes\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport rasterio\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport matplotlib.colors as mcolors\n\nmosaic_path = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2010-naip.tif'\n\n# Open the raster file\nwith rasterio.open(mosaic_path) as src:\n    classified_img = src.read(1)  # Read the first (only) band\n    nodata_value = src.nodata  # Check the NoData value, if exists\n\n# Check unique values in the raster (to understand classification)\nprint(f\"Unique values in the classified raster: {np.unique(classified_img)}\")\nprint(f\"NoData value: {nodata_value}\")\n\n# Handle NoData values (e.g., replace them with a specific value if needed)\nif nodata_value is not None:\n    classified_img[classified_img == nodata_value] = 0  # Replace NoData with 0 or any appropriate value\n\n# Set all values except Class 7 to 0 (background value)\nclassified_img[classified_img != 7] = 0\n\n# Define a custom colormap with one color for Class 7 (and background for the rest)\ncmap = mcolors.ListedColormap([\n    '#FFFFFF',  # Background (0)\n    '#e377c2'   # Class 7 - Pink (highlighted)\n])\n\n# Create the legend labels corresponding to the class values\nlegend_labels = ['Background', 'Class 7 - Pink']\n\n# Plot the classified raster with the custom colormap\nplt.figure(figsize=(10, 8))\nimshow_obj = plt.imshow(classified_img, cmap=cmap, vmin=0, vmax=1)  # Set the range of classes to 0 and 1 for Class 7\n\nplt.title(\"2010 Land Cover Classification - Class 7 Only\")\nplt.axis(\"off\")  # Hide axis ticks\n\n# Create a custom legend for the classes\nhandles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cmap(i), markersize=10) for i in range(2)]\nplt.legend(handles, legend_labels, title=\"Classes\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n\nplt.show()\n\nUnique values in the classified raster: [1 2 3 4 5 6 7]\nNoData value: None\n\n\n\n\n\n\n\n\n\n\nimport rasterio\n\n# Path to the classified raster file\nmosaic_path = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2022-naip.tif'\n\n# Open the raster file to access metadata\nwith rasterio.open(mosaic_path) as src:\n    # Get pixel size (resolution)\n    pixel_size = src.res  # This gives (pixel_width, pixel_height) in map units (meters, feet, etc.)\n    \n    # Calculate pixel area (in square meters, assuming the raster is in meters)\n    pixel_area = pixel_size[0] * pixel_size[1]\n    \n    print(f\"Pixel size (width x height): {pixel_size}\")\n    print(f\"Pixel area (in square units): {pixel_area}\")\n\nPixel size (width x height): (0.6, 0.6)\nPixel area (in square units): 0.36\n\n\n\nimport rasterio\nimport numpy as np\n\n# Path to the classified raster file\nmosaic_path = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2022-naip.tif'\n\n# Open the raster file to access the data and metadata\nwith rasterio.open(mosaic_path) as src:\n    classified_img = src.read(1)  # Read the first (only) band\n    nodata_value = src.nodata  # Check the NoData value, if exists\n    pixel_size = src.res  # This gives (pixel_width, pixel_height) in feet\n    pixel_area = pixel_size[0] * pixel_size[1]  # Pixel area in square feet\n    \n# Handle NoData values (e.g., replace them with a specific value if needed)\nif nodata_value is not None:\n    classified_img[classified_img == nodata_value] = 0  # Replace NoData with 0 or any appropriate value\n\n# Get unique classes and their counts\nunique_classes, counts = np.unique(classified_img, return_counts=True)\n\n# Calculate the area for each class (in square feet)\nclass_areas_ft2 = counts * pixel_area  # Area = pixel count * pixel area (square feet)\n\n# Print the area for each class\nfor class_id, area in zip(unique_classes, class_areas_ft2):\n    print(f\"Class {class_id} area: {area} square feet\")\n\n# Plotting the bar plot for class areas\nplt.figure(figsize=(10, 6))\nplt.bar(unique_classes, class_areas_ft2, color='skyblue')\nplt.xlabel('Class ID')\nplt.ylabel('Area (square feet)')\nplt.title('Area of Each Class in Square Feet')\nplt.xticks(unique_classes)  # Ensure each class has a label on the x-axis\nplt.tight_layout()\nplt.show()\n\nClass 1 area: 30810.96 square feet\nClass 2 area: 49219.56 square feet\nClass 3 area: 1103006.88 square feet\nClass 4 area: 691481.16 square feet\nClass 5 area: 79008.84 square feet\nClass 6 area: 5439.96 square feet\nClass 7 area: 28306.079999999998 square feet\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\nimport matplotlib.colors as mcolors\n\n# List of raster file paths for different years\nraster_paths = [\n    'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2010-naip.tif',\n    'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2013-naip.tif',\n    'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2017-naip.tif',\n    'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2019-naip.tif',\n    'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-classified/classified_mask2022-naip.tif'\n]\n\n# Function to calculate the area for each class in a raster\ndef calculate_area(raster_path):\n    with rasterio.open(raster_path) as src:\n        classified_img = src.read(1)  # Read the first (only) band\n        nodata_value = src.nodata  # Check the NoData value, if exists\n        pixel_size = src.res  # This gives (pixel_width, pixel_height) in feet\n        pixel_area = pixel_size[0] * pixel_size[1]  # Pixel area in square feet\n\n    # Handle NoData values (e.g., replace them with a specific value if needed)\n    if nodata_value is not None:\n        classified_img[classified_img == nodata_value] = 0  # Replace NoData with 0 or any appropriate value\n\n    # Get unique classes and their counts\n    unique_classes, counts = np.unique(classified_img, return_counts=True)\n\n    # Calculate the area for each class (in square feet)\n    class_areas_ft2 = counts * pixel_area  # Area = pixel count * pixel area (square feet)\n    \n    return unique_classes, class_areas_ft2\n\n# Plotting the comparison for all years\nplt.figure(figsize=(12, 8))\n\n# Define class names and colors for the plot (based on your previous classes)\nlegend_labels = [\n    'Barren Land', \n    'Developed Open Space', \n    'Buildings', \n    'Background', \n    'Green Space (Park)', \n    'Developed Low Density', \n    'Other'\n]\n\n# Define the custom color map for the bars (same colors as in your initial request)\ncmap = mcolors.ListedColormap([\n    '#B3AFA5',  # Class 1 - Barren Land\n    '#E1CDCD',  # Class 2 - Developed Open Space\n    '#AA1E22',  # Class 3 - Buildings\n    '#FFFFFF',  # Class 4 - Background\n    '#6CAB67',  # Class 5 - Green Space (Park)\n    '#DC9881',  # Class 6 - Developed Low Density\n    '#e377c2'   # Class 7 - Other\n])\n\n# Years corresponding to the rasters\nyears = ['2010', '2013', '2017', '2019', '2022']\n\n# Store the areas for each year\nall_class_areas = {}\n\n# Loop over each raster to calculate the areas and store them\nfor i, raster_path in enumerate(raster_paths):\n    unique_classes, class_areas_ft2 = calculate_area(raster_path)\n    all_class_areas[years[i]] = class_areas_ft2\n\n# Plotting the area comparison for each class across the years\nbar_width = 0.15\nindex = np.arange(len(legend_labels))  # Adjust to the number of classes (7)\n\n# Creating bars for each year\nfor i, year in enumerate(years):\n    plt.bar(index + (i - 2) * bar_width, all_class_areas[year], bar_width, label=year, color=cmap.colors)\n\n# Adding labels, title, and legend\nplt.xlabel('Class')\nplt.ylabel('Area (square feet)')\nplt.title('Comparison of Class Areas Across Years (2010-2022)')\nplt.xticks(index, legend_labels, rotation=45, ha='right')  # Adjust x-ticks for classes\nplt.legend(title=\"Year\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Step 2: If the CRS doesn't match, reproject the shapefile to match the raster's CRS\nshapefile_path = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/StudyArea_reprojected_mosaic.shp'\nraster_path = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/land_use_resampled.tif'\n\n# Load the shapefile using geopandas\nstudy_area = gpd.read_file(shapefile_path)\n\n# Reproject the shapefile to the raster's CRS if needed\nwith rasterio.open(raster_path) as src:\n    raster_crs = src.crs\n\n# Reproject if CRS does not match\nif study_area.crs != raster_crs:\n    study_area = study_area.to_crs(raster_crs)\n    print(\"Shapefile CRS reprojected to match raster CRS\")\n# Step 3: Clip the raster using the study area (polygon geometry)\nwith rasterio.open(raster_path) as src:\n    # Get the geometries of the study area\n    geometries = study_area.geometry.values  # Assuming study area is in polygon format\n    \n    # Use rasterio.mask to apply the geometry mask on the raster\n    out_image, out_transform = mask(src, geometries, crop=True)\n    out_meta = src.meta\n\n# Step 4: Update the metadata to reflect the changes (cropped raster)\nout_meta.update({\n    \"driver\": \"GTiff\",\n    \"count\": 1,\n    \"dtype\": \"float32\",  # Update according to your raster data type\n    \"crs\": raster_crs,\n    \"transform\": out_transform\n})\n\n# Step 5: Display the clipped raster\nplt.figure(figsize=(10, 8))\nplt.imshow(out_image[0], cmap=\"tab10\")  # Plot the first band (assuming single-band raster)\nplt.colorbar(label=\"Land Use Class\")\nplt.title(\"Clipped Land Use Raster\")\nplt.axis(\"off\")  # Hide axis ticks\nplt.show()\n\n\n---------------------------------------------------------------------------\nCPLE_OpenFailedError                      Traceback (most recent call last)\nFile rasterio\\\\_base.pyx:310, in rasterio._base.DatasetBase.__init__()\n\nFile rasterio\\\\_base.pyx:221, in rasterio._base.open_dataset()\n\nFile rasterio\\\\_err.pyx:221, in rasterio._err.exc_wrap_pointer()\n\nCPLE_OpenFailedError: C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/land_use_resampled.tif: No such file or directory\n\nDuring handling of the above exception, another exception occurred:\n\nRasterioIOError                           Traceback (most recent call last)\nCell In[24], line 9\n      6 study_area = gpd.read_file(shapefile_path)\n      8 # Reproject the shapefile to the raster's CRS if needed\n----&gt; 9 with rasterio.open(raster_path) as src:\n     10     raster_crs = src.crs\n     12 # Reproject if CRS does not match\n\nFile c:\\Users\\19397\\.conda\\envs\\geospatial\\Lib\\site-packages\\rasterio\\env.py:451, in ensure_env_with_credentials.&lt;locals&gt;.wrapper(*args, **kwds)\n    448     session = DummySession()\n    450 with env_ctor(session=session):\n--&gt; 451     return f(*args, **kwds)\n\nFile c:\\Users\\19397\\.conda\\envs\\geospatial\\Lib\\site-packages\\rasterio\\__init__.py:304, in open(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\n    301 path = _parse_path(raw_dataset_path)\n    303 if mode == \"r\":\n--&gt; 304     dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n    305 elif mode == \"r+\":\n    306     dataset = get_writer_for_path(path, driver=driver)(\n    307         path, mode, driver=driver, sharing=sharing, **kwargs\n    308     )\n\nFile rasterio\\\\_base.pyx:312, in rasterio._base.DatasetBase.__init__()\n\nRasterioIOError: C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/land_use_resampled.tif: No such file or directory\n\n\n\n\nimport fiona\nfrom matplotlib import pyplot as plt\nimport rasterio\nfrom rasterio.mask import mask  # Import the mask function from rasterio.mask\ndef display_naip_tile(filename, dsfactor = 2):\n    \"\"\"\n    Display a NAIP tile using rasterio.\n    \n    dsfactor: downsample factor\n    For .mrf-formatted tiles (which span multiple files), 'filename' should refer to the \n    .mrf file.\n    \"\"\"\n    \n    # NAIP tiles are enormous; downsize for plotting in this notebook\n    \n    with rasterio.open(filename) as raster:\n        # rasterio uses 1-based indexing for channels.\n        h = int(raster.height/dsfactor)\n        w = int(raster.width/dsfactor)\n        print('Resampling to {},{}'.format(h,w))\n        ir = raster.read(4, out_shape=(1, h, w))\n        r = raster.read(1, out_shape=(1, h, w))\n        g = raster.read(2, out_shape=(1, h, w))\n        \n    cir = np.dstack((ir,r,g))\n    fig = plt.figure(figsize=(7.5, 7.5), dpi=100, edgecolor='k')\n    plt.imshow(cir)\n    raster.close()\n\ninput_value_raster = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/lu_philly.tif'\nshpfile = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/StudyArea_reprojected_mosaic.shp'\nout_raster = 'C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/mask-lu.tif'\n\n\nwith fiona.open(shpfile, \"r\") as shapefile:\n    shapes = [feature[\"geometry\"] for feature in shapefile]\n\nwith rasterio.open(input_value_raster) as src:\n    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n    out_meta = src.meta\n\nout_meta.update({\"driver\": \"GTiff\",\n                 \"height\": out_image.shape[1],\n                 \"width\": out_image.shape[2],\n                 \"count\": out_image.shape[0],  # Ensure correct number of bands\n                 \"dtype\": out_image.dtype,  # Ensure correct data type\n                 \"compress\": None,\n                 \"transform\": out_transform})\n\nwith rasterio.open(out_raster, \"w\", **out_meta) as dest:\n    dest.write(out_image)\n\ndisplay_naip_tile('C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/mask-lu.tif')\n\nResampling to 934,1379\n\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[21], line 53\n     50 with rasterio.open(out_raster, \"w\", **out_meta) as dest:\n     51     dest.write(out_image)\n---&gt; 53 display_naip_tile('C:/Users/19397/Documents/GitHub/MUSA_6950/ai-urban-sustainability/lab6-machine-learning/CT-data/mask-lu.tif')\n\nCell In[21], line 21, in display_naip_tile(filename, dsfactor)\n     19 w = int(raster.width/dsfactor)\n     20 print('Resampling to {},{}'.format(h,w))\n---&gt; 21 ir = raster.read(4, out_shape=(1, h, w))\n     22 r = raster.read(1, out_shape=(1, h, w))\n     23 g = raster.read(2, out_shape=(1, h, w))\n\nFile rasterio\\\\_io.pyx:535, in rasterio._io.DatasetReaderBase.read()\n\nIndexError: band index 4 out of range (not in (1,))\n\n\n\n\n# Open the raster file\nwith rasterio.open(out_raster) as src:\n    classified_img = src.read(1)  # Read the first (only) band\n    nodata_value = src.nodata  # Check the NoData value, if exists\n\n# Check unique values in the raster (to understand classification)\nprint(f\"Unique values in the classified raster: {np.unique(classified_img)}\")\nprint(f\"NoData value: {nodata_value}\")\n\n# Handle NoData values (e.g., replace them with a specific value if needed)\nif nodata_value is not None:\n    classified_img[classified_img == nodata_value] = 0  # Replace NoData with 0 or any appropriate value\n\n# Plot the classified raster\n# Plot the classified raster\nplt.figure(figsize=(10, 8))\nplt.imshow(classified_img, cmap=\"tab10\")  # 'tab10' provides distinct colors\nplt.colorbar(label=\"Land Cover Class\")  # Optional colorbar\nplt.title(\"2010\")\nplt.axis(\"off\")  # Hide axis ticks\nplt.show()",
    "crumbs": [
      "Reproducible Analysis",
      "Land Cover Change Analysis"
    ]
  }
]